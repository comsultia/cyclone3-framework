#!/usr/bin/env c3-job
package Cyclone3::job;
use parent 'TOM::Engine::job::module';
use open ':utf8', ':std';
use if $] < 5.018, 'encoding','utf8';
use utf8;
use strict;

use Ext::Elastic::_init;
use DateTime;
use Data::Dumper;

sub sec2human {
	my $seconds = shift;
	my $string = join ":", map { sprintf "%02d", $_} (gmtime($seconds))[7,2,1,0]; 
	$string=~s/\G00://g;
	$string=~s|(\d\d):(\d\d):(\d\d):(\d\d)$|$1d:$2h:$3m:$4s|
		|| $string=~s|(\d\d):(\d\d):(\d\d)$|$1h:$2m:$3s|
		|| $string=~s|(\d\d):(\d\d)$|$1m:$2s|
		|| $string=~s|(\d\d)$|$1s|;
	return $string;
}

sub execute
{
	my $self=shift;
	my $env=$self->env;
	if (!$env->{'force'}){
		return if $self->running({'max'=>(3600*12),'unique'=>$TOM::hostname.'::'.$tom::H}); # check if not already running
	}
	alarm(3600*12);
	
	if (!$Ext::Elastic_rlog && !$Ext::Elastic)
	{
		return 1;
	}
	
	$Ext::Elastic = $Ext::Elastic_rlog
		|| $Ext::Elastic;	
	$Ext::Elastic->{'request_timeout'} = 300;
	
	my $Elastic=Search::Elasticsearch->new($Ext::Elastic);
	
	if (!$Elastic)
	{
		return 1;
	}
	
	my @filter=[{"terms" => {"hd" => [$TOM::domain || 'undef']}}];
	my @filter;
	if ($TOM::DEBUG_log_type{'.onlyhost'})
	{
		undef $Ext::Elastic_rlog->{'_manage'};
		push @filter,{"term" => {"h" => $TOM::hostname.'.'.$TOM::domain}};
	}
	push @filter,{
		'bool' => {
			'must_not' => [
				{"terms" => {"s" => [1]}}
			]
		}
	};
	
	if ($tom::H)
	{
		main::_log("clean in domain mode '$tom::H'");
		push @filter,{"terms" => {"d" => [$tom::H]}};
		if (!$TOM::DEBUG_log_type{'.modified'})
		{
			main::_log("not configured TOM::DEBUG_log_type for this domain, exit");
			return 1;
		}
	}
	
	my @indices_list;
	
#	main::_log("get list of indices");
	my $indices=$Elastic->indices->stats('index' => 'logstash-*')->{'indices'};
	my $settings=$Elastic->indices->get_settings('index' => 'logstash-*');
	foreach my $indice (sort keys %{$indices})
	{
#		print Dumper($indices->{$indice});
#		main::_log("$indice");
		push @indices_list, $indice;
	}
	
	# try to merge month indices
	my @month_indices=(grep {$_=~/logstash\-\d\d\d\d\-\d\d$/} sort @indices_list);
	   pop @month_indices;pop @month_indices;
	my %year_indices;
	foreach my $indice (@month_indices) # merge by years
	{
		$indice=~/logstash\-(\d\d\d\d)/;
		push @{$year_indices{$1}}, $indice;
	}
	foreach my $year (reverse sort keys %year_indices)
	{
		if (scalar @{$year_indices{$year}} == 12)
		{
			unshift @indices_list, 'logstash-'.$year.'-*';
		}
		else
		{
			unshift @indices_list, join(',',@{$year_indices{$year}});
		}
		foreach my $indice (@{$year_indices{$year}})
		{
			@indices_list=(grep {not $_ eq $indice} @indices_list);
		}
	}

	# try to merge day indices
	my @day_indices=(grep {$_=~/logstash\-\d\d\d\d\-\d\d\-\d\d$/} sort @indices_list);
	   pop @day_indices;pop @day_indices;pop @day_indices;
	my %week_indices;
	foreach my $indice (@day_indices) # merge by weeks
	{
		$indice=~/logstash\-(\d\d\d\d)\-(\d\d)\-(\d\d)/;
		my $dt = DateTime->new('year' => $1, 'month' => $2, 'day' => $3);
		push @{$week_indices{$1.'-'.$dt->week_number()}}, $indice;
	}
	foreach my $week (reverse sort keys %week_indices)
	{
		unshift @indices_list, join(',',@{$week_indices{$week}});
		foreach my $indice (@{$week_indices{$week}})
		{
			@indices_list=(grep {not $_ eq $indice} @indices_list);
		}
	}

	if ($env->{'indice'})
	{
		@indices_list=($env->{'indice'});
	}
#	return 1;
	
	my $already_something_removed;
	
#	foreach my $indice (sort {int(rand(3))-1} @indices_list)
	foreach my $indice (sort @indices_list)
	{
		# at first, search oldest entry
		my $results = $Elastic->search(
			'index' => $indice,
			'type' => 'fluentd',
			'body'  => {
#				'timeout' => 10000, # 10 seconds
				"size" => 1,
				"aggregations" => {
					"oldest" => {
						"min" => {
							'field' => "\@timestamp"
						}
					}
				}
			}
		);
		
		#my $old=
		my $old = int((time() - int($results->{'aggregations'}->{'oldest'}->{'value'}/1000))/8640)/10;
		my $removed;
		
		if (not($indice=~/\*$/) && not($indice=~/,/) && ($tom::Thour >= 18 || $tom::Thour <= 6) && 0) # do it only when developers sleep
		{
#			main::_log("'$indice' $old days " . ($TOM::DEBUG_log_type{'pub'}{'max_days'}+3));
			if (!$tom::H
				&& $Ext::Elastic_rlog->{'_manage'}
				&& ($old > ($TOM::DEBUG_log_type{'pub.track'}{'max_days'} + 7))
				&& $indice=~/\d\d\d\d\-\d\d\-\d\d$/)
			{
				my $indice_new=$indice;
					$indice_new=~s/\-\d\d$//;
				main::_log("'$indice' is old dayindex, moving to monthindex '$indice_new'");
				
				my $i;
				my $bulk_delete = $Elastic->bulk_helper(
					'index'		=> $indice,
					'type'  		=> 'fluentd',
					'verbose'	=> 0,
				);
				my $bulk = $Elastic->bulk_helper(
					'index'		=> $indice_new,
					'type'  		=> 'fluentd',
					'verbose'	=> 0,
					'on_success'  => sub {
						my ($action,$response) = @_;
						$i++;
						main::_log("  reindex [$i]") if ($i/100000 == int($i/100000));
						$bulk_delete->delete({'id' => $response->{'_id'}});
					},
				);
				
				eval {
				$bulk->reindex(
					'source'  => {
						'index'			=>	$indice,
						'size'			=>	1000,
						'search_type'	=>	'scan',
					}
				);
				};
				if ($@)
				{
					main::_log("error in reindex ".$@,1);
				}
				
				$bulk->flush();
				$bulk_delete->flush();
				
				main::_log(" moved");
			}
			
		}
		
		main::_log("'$indice' preparing data removal (indice old $old days)");
		
		# at second, create facet
		my $results = $Elastic->search(
			'index' => $indice,
			'type' => 'fluentd',
			'body'  => {
#				'timeout' => 10000, # 10 seconds
				
				"size" => 0,
				"aggregations" => {
					"top_t" => {
						"terms" => {
							'field' => "t",
							"size" => 200,
						}
					}
				},
				'query' => {
					'bool' => {
						'filter' => [
							@filter
						]
					}
				}
			}
		);
		
		foreach my $type (@{$results->{'aggregations'}->{'top_t'}->{'buckets'}})
		{
			$type->{'key'}=~s|^cyclone3\.||;
			
			main::_log(" '$type->{'key'}' docs=$type->{'doc_count'}");
			
			my $max_days=$TOM::DEBUG_log_type{$type->{'key'}}->{'max_days'} || $TOM::DEBUG_log_type{'_default'}->{'max_days'};
			
			if ($max_days <= $old)
			{
				my  $max_days_syntax=$max_days.'d';
					$max_days_syntax=int($max_days*24).'h' if $max_days=~/\./;

				main::_log("  remove older than $max_days_syntax");

				my $bulk_delete = $Elastic->bulk_helper(
					'index'		=> $indice,
					'type'  		=> 'fluentd',
					'verbose'	=> 0,
					'max_count' => 1000
				);
				
				my $scroll = $Elastic->scroll_helper(
					'index'       => $indice,
#					'search_type' => 'scan',
					'size'        => 500,
					'_source' => ['_id'],
					'body'  => {
						'query' => {
							'bool' => {
								'filter' => [
									{"terms" => {"t" => [$type->{'key'},"cyclone3.".$type->{'key'}]}},
									{
										"range" => {
											'@timestamp' => {
												"lt" => 'now-'.$max_days_syntax
											}
										}
									},@filter
								]
							}
						},
					}
				);
				
				main::_log("  found ".$scroll->total." docs to remove");
				my $i;
				my $time_start=time();
				while (my $response = $scroll->next) {
					# do something
					$i++;
					if ($i/10000 == int($i/10000))
					{
						my $speed=$i/(time()-$time_start); # docs/s
						my $eta=int(($scroll->total - $i)/$speed);
						main::_log("   removed $i docs eta ".sec2human($eta)." speed ".int($speed)."docs/s");
					}
					if ($i/1000 == int($i/1000))
					{
#						$bulk_delete->flush();
					}
					$bulk_delete->delete({'id' => $response->{'_id'},'index'=>$response->{'_index'}});
					$already_something_removed=1 unless $already_something_removed;
					$removed=1 unless $removed;
				}
				$bulk_delete->flush();
				
			}
			
			if ($TOM::DEBUG_log_type{$type->{'key'}}->{'fault'})
			{
				$max_days=$TOM::DEBUG_log_type{$type->{'key'}}->{'fault'};
				
				next if $max_days > $old;
				
				main::_log("  remove faults older than $max_days days");
				
				
				my $bulk_delete = $Elastic->bulk_helper(
					'index'		=> $indice,
					'type'  		=> 'fluentd',
					'verbose'	=> 0,
				);
				
				my $scroll = $Elastic->scroll_helper(
					'index'       => $indice,
#					'search_type' => 'scan',
					'size'        => 500,
					'_source' => ['_id'],
					'body'  => {
						'query' => {
							'bool' => {
								'filter' => [
									{"terms" => {"t" => ["cyclone3.".$type->{'key'}]}},
									{"terms" => {"f" => [1]}},
									{
										"range" => {
											'@timestamp' => {
												"lt" => 'now-'.$max_days.'d'
											}
										}
									},@filter
								]
							}
						},
					}
				);
				
				main::_log("  found ".$scroll->total." docs to remove");
				my $i;
				my $time_start=time();
				while (my $response = $scroll->next) {
					# do something
					$i++;
					if ($i/10000 == int($i/10000))
					{
						my $speed=$i/(time()-$time_start); # docs/s
						my $eta=int(($scroll->total - $i)/$speed);
						main::_log("   removed $i docs eta ".sec2human($eta)." speed ".int($speed)."docs/s");
					}
					$bulk_delete->delete({'id' => $response->{'_id'}});
					$already_something_removed=1 unless $already_something_removed;
					$removed=1 unless $removed;
				}
				$bulk_delete->flush();
				
			}
			
			if ($TOM::DEBUG_log_type{$type->{'key'}}->{'levels'})
			{
				foreach my $level (sort keys %{$TOM::DEBUG_log_type{$type->{'key'}}->{'levels'}})
				{
					$max_days=$TOM::DEBUG_log_type{$type->{'key'}}->{'levels'}->{$level};
					
					next if $max_days > $old;
					
					main::_log("  remove level >=$level older than $max_days days");
					
					my $bulk_delete = $Elastic->bulk_helper(
						'index'		=> $indice,
						'type'  		=> 'fluentd',
						'verbose'	=> 0,
					);
					
					my $scroll = $Elastic->scroll_helper(
						'index'       => $indice,
	#					'search_type' => 'scan',
						'size'        => 500,
						'_source' => ['_id'],
						'body'  => {
							'query' => {
								'bool' => {
									'filter' => [
										{"terms" => {"t" => ["cyclone3.".$type->{'key'}]}},
										{"range" => {"l" => {'gte' => $level}}},
										{
											"range" => {
												'@timestamp' => {
													"lt" => 'now-'.$max_days.'d'
												}
											}
										},@filter
									],
									'must_not' => [
										{"terms" => {"f" => [1]}},
									]
								}
							},
						}
					);
					
					main::_log("  found ".$scroll->total." docs to remove");
					my $i;
					my $time_start=time();
					while (my $response = $scroll->next) {
						# do something
						$i++;
						if ($i/10000 == int($i/10000))
						{
							my $speed=$i/(time()-$time_start); # docs/s
							my $eta=int(($scroll->total - $i)/$speed);
							main::_log("   removed $i docs eta ".sec2human($eta)." speed ".int($speed)."docs/s");
						}
						$bulk_delete->delete({'id' => $response->{'_id'}});
						$already_something_removed=1 unless $already_something_removed;
						$removed=1 unless $removed;
					}
					$bulk_delete->flush();
					
				}
			}
		}
		
		if ($already_something_removed && !$removed)
		{
#			main::_log("this was last indice to try find something to remove");
#			last;
		}
		
	}
	
return 1}
1;
